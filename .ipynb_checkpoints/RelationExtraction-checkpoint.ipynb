{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "s2OsKlUseX_0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "class RelationExtraction(Dataset):\n",
    "    def __init__(\n",
    "      self,\n",
    "      path: str,  \n",
    "      vocab_size: int = 5_000,  \n",
    "    ):\n",
    "        \n",
    "        self.data = pd.read_csv(path, index_col=0)\n",
    "        self.data.columns = ['text', 'labels']\n",
    "        self.data['labels'] = self.data['labels'].str.replace('none', '')\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def encode_tokens(self, ):\n",
    "#         encoded = [self.vocab.get(token, self.default) for token in tokens]\n",
    "#         return torch.tensor(encoded, device=device)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, n: int):\n",
    "#         text = self.data['text'].iloc[n]\n",
    "#         labels = self.data['labels'].iloc[n]\n",
    "#     return self.encode_tokens(self.tokenize(text)), self.encode_label(labels)\n",
    "        pass\n",
    "    \n",
    "    def tokenize(self, data: str):\n",
    "        for text in data['text']:\n",
    "            tokens = tokenizer(text)\n",
    "        return [token.text for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "ID                                                        \n",
      "0                  who plays luke on star wars new hope   \n",
      "1                        show credits for the godfather   \n",
      "2                who was the main actor in the exorcist   \n",
      "3     find the female actress from the movie she's t...   \n",
      "4                       who played dory on finding nemo   \n",
      "...                                                 ...   \n",
      "2307               what was the revenue for toy story 3   \n",
      "2308                                dark knight revenue   \n",
      "2309               how much did the dark night generate   \n",
      "2310                  can i see the lion king's revenue   \n",
      "2311         can i see what the lion king's revenue was   \n",
      "\n",
      "                                             labels  \n",
      "ID                                                   \n",
      "0     movie.starring.actor movie.starring.character  \n",
      "1                              movie.starring.actor  \n",
      "2                              movie.starring.actor  \n",
      "3                 movie.starring.actor actor.gender  \n",
      "4     movie.starring.actor movie.starring.character  \n",
      "...                                             ...  \n",
      "2307                            movie.gross_revenue  \n",
      "2308                            movie.gross_revenue  \n",
      "2309                            movie.gross_revenue  \n",
      "2310                            movie.gross_revenue  \n",
      "2311                            movie.gross_revenue  \n",
      "\n",
      "[2312 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# RelationExtraction Initiation \n",
    "re = RelationExtraction('hw1_train-1.csv')\n",
    "print(re.data)\n",
    "\n",
    "# A small batch size of 2 makes it easier to debug for printing. \n",
    "data_loader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_tokens, \n",
    "        emb_dim, \n",
    "        hidden_dim, \n",
    "        output_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_tokens, emb_dim)\n",
    "        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, optimizer, loss_fn):\n",
    "    pass\n",
    "\n",
    "def evaluate(loader, model, loss_fn, score_fn):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "score_fn = accuracy_score\n",
    "n_epochs = 3\n",
    "best_acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    avg_loss = train(train_loader, model, optimizer, loss_fn)\n",
    "    print('train loss: ', avg_loss)\n",
    "    accuracy = evaluate(val_loader, model, loss_fn, score_fn)\n",
    "    print('val accuracy: ', accuracy)\n",
    "    if accuracy > best_acc and accuracy > 0.7:\n",
    "        torch.save(model.state_dict(), f'best-model.pt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
